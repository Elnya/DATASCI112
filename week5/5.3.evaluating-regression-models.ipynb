{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "766096c4",
   "metadata": {},
   "source": [
    "# Evaluating Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244c2760",
   "metadata": {},
   "source": [
    "## Training and Test Data\n",
    "\n",
    "The data for which we know the label $y$ is called the **training data.**\n",
    "\n",
    "The data for which we don't know $y$ (and want to predict it) is called the **test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4c8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/bordeaux.csv\", index_col=\"year\")\n",
    "df_train = df.loc[:1980].copy()\n",
    "df_test = df.loc[1981:].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79072fe6",
   "metadata": {},
   "source": [
    "Let's seperate the inputs $X$ from the labels $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cc6c5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[[\"win\", \"summer\"]]\n",
    "y_train = df_train[\"price\"]\n",
    "\n",
    "X_test = df_test[[\"win\", \"summer\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2f272",
   "metadata": {},
   "source": [
    "## $K$-Nearest Neighbors\n",
    "\n",
    "We've seen one machine learning model: $k$-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e016224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35.8, 54. , 52.2, 18.4, 35.6, 13.2, 37. , 51.4, 36.6, 36.6, 40.6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsRegressor(n_neighbors=5)\n",
    ")\n",
    "\n",
    "pipeline.fit(X=X_train, y=y_train)\n",
    "pipeline.predict(X=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf4526b",
   "metadata": {},
   "source": [
    "*Today*: How do we know if this model is any good?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609af34",
   "metadata": {},
   "source": [
    "## Prediction Error\n",
    "\n",
    "If the true labels are $y_1, \\dots, y_n$ and our model predicts $\\hat{y}_1, \\dots, \\hat{y}_n,$ how do we measure how well our model did?\n",
    "\n",
    "- **mean squared error (MSE)**\n",
    "\n",
    "$$\n",
    "\\mathsf{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "- **mean absolute error (MAE)**\n",
    "\n",
    "$$\n",
    "\\mathsf{MAE} = \\frac{1}{n}\\sum_{i=1}^{n}|y_i - \\hat{y}_i|\n",
    "$$\n",
    "\n",
    "Calculating MSE or MAE requires data where true labels are known. Where can we find such data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f0d764",
   "metadata": {},
   "source": [
    "## Training Error\n",
    "\n",
    "On the training data, the true labels $y_1, \\dots, y_n$ are known.\n",
    "\n",
    "Let's calculate the **training error** of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09cd8dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(207.24148148148146)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X=X_train, y=y_train)\n",
    "y_train_ = pipeline.predict(X=X_train)\n",
    "((y_train - y_train_) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6688d13",
   "metadata": {},
   "source": [
    "There's also a Scikit-Learn function for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102600dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207.24148148148146"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_true=y_train, y_pred=y_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187d7b4",
   "metadata": {},
   "source": [
    "How do we intrepret this MSE of $207.24$? <br />\n",
    "Remember, we are predicting the price of wine. So the model is off by 208.24 square dollars on average.\n",
    "\n",
    "The square root is easier to interpret. The model is off by $\\sqrt{207.24} \\approx \\$14.40$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde224d",
   "metadata": {},
   "source": [
    "## The Problem with Training Error\n",
    "\n",
    "What's the training error of a $1$-nearest neighbor model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59707b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    KNeighborsRegressor(n_neighbors=1)\n",
    ")\n",
    "pipeline.fit(X=X_train, y=y_train)\n",
    "y_train_ = pipeline.predict(X=X_train)\n",
    "mean_squared_error(y_true=y_train, y_pred=y_train_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7a0a60",
   "metadata": {},
   "source": [
    "Why did this happen? <br />\n",
    "The 1-nearest neighbor to any observatoiin in the training data is the observation itself!\n",
    "\n",
    "A 1-nearest neighbor model will always be perfect on the training data. But is it necessarily the best model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd357e7",
   "metadata": {},
   "source": [
    "## Test Error\n",
    "\n",
    "We don't need to know how well our model does on *training data.*\n",
    "\n",
    "We want to know how well it will do on *test data.*\n",
    "\n",
    "In general, test error $>$ training error.\n",
    "\n",
    "Analogy: A professor posts a practice exam before an exam.\n",
    "- If the actual exam is the same as the practice exam, how many points will students miss? That's training error.\n",
    "- If the actual exam is different from the practice exam, how many points will students miss? That's test error.\n",
    "\n",
    "It's always easier to answer questions that you've seen before than questions you haven't seen.\n",
    "\n",
    "*Now:* How do we estimate the test error?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18446eef",
   "metadata": {},
   "source": [
    "## Validation Set\n",
    "\n",
    "The training data is the only data we have, where the true labels $y$ are known.\n",
    "\n",
    "So one way to estimate the test error is to not use all of the training data to fit the model, leaving the remaining data for estimating the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ca2e0",
   "metadata": {},
   "source": [
    "## Implementing the Validation Set\n",
    "\n",
    "First, we choose half of the vintages in the training data to be in the training set. The remaining vintages will be in the validation set.\n",
    "\n",
    "We can set a [random seed](https://en.wikipedia.org/wiki/Random_seed) to ensure reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba51494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1955, 1978, 1968, 1971, 1959, 1965, 1977, 1967, 1973, 1974, 1970,\n",
       "       1953, 1964])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "inds_train_set = np.random.choice(df_train.index, size=len(df_train) // 2, replace=False)\n",
    "inds_train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5646193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_set = df_train.loc[inds_train_set]\n",
    "df_val_set = df_train.drop(inds_train_set, axis=\"rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c4c09",
   "metadata": {},
   "source": [
    "Notice that since both the training and validation sets came from the training data, both the inputs $X$ and the labels $y$ are known."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "673fb18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, y_train_set = df_train_set[[\"win\", \"summer\"]], df_train_set[\"price\"]\n",
    "X_val_set, y_val_set = df_val_set[[\"win\", \"summer\"]], df_val_set[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10afc17c",
   "metadata": {},
   "source": [
    "Now, let's fit a 1-nearest neighbors model to the training set and calculate the MSE of the predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "470d80fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.71428571428572"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = make_pipeline(\n",
    "          StandardScaler(),\n",
    "          KNeighborsRegressor(n_neighbors=1))\n",
    "pipeline.fit(X_train_set, y_train_set)\n",
    "y_val_set_ = pipeline.predict(X_val_set)\n",
    "mean_squared_error(y_val_set, y_val_set_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de8d2b5",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The way we split the data into two halves was arbitrary.\n",
    "\n",
    "Why not use the 2nd half for training and the 1st half for validation?\n",
    "\n",
    "This is called **cross-validatation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca4c051",
   "metadata": {},
   "source": [
    "## Implementing Cross-Validation from Scratch\n",
    "\n",
    "Previously, we fit the model to the training set and evaluated the predictions on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4498bf95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195.71428571428572"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train_set, y_train_set)\n",
    "y_val_set_ = pipeline.predict(X_val_set)\n",
    "mean_squared_error(y_val_set, y_val_set_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0080b",
   "metadata": {},
   "source": [
    "Now let's do the same thing, but with the roles of the training and validation sets reversed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fd612d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "306.9230769230769"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_val_set, y_val_set)\n",
    "y_train_set_ = pipeline.predict(X_train_set)\n",
    "mean_squared_error(y_train_set, y_train_set_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ffebd",
   "metadata": {},
   "source": [
    "Wow, the estimates can be quite different!\n",
    "\n",
    "To come up with one overall estimate of the test error, we can average them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66e6966a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251.315"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(195.71 + 306.92) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a2ea3",
   "metadata": {},
   "source": [
    "## $K$-Fold Cross Validation\n",
    "\n",
    "One problem with splitting the data into two is that we only fit the model on half of the data.\n",
    "\n",
    "A model trained on half of the data may be very different from a model trained on all of the data.\n",
    "\n",
    "It may be better to split the data into $K$ samples and come up with $K$ validation errors.\n",
    "\n",
    "This way, we use $1−1/K$ of the data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b0bfb",
   "metadata": {},
   "source": [
    "## Implementing Cross-Validation in Scikit-Learn\n",
    "\n",
    "You specify the model, data, and $K$. Scikit-Learn will:\n",
    "- split the training data into $K$ samples\n",
    "- hold out one sample at a time as a validation set\n",
    "    - fit the model to remaining $1−1/K$ of the data\n",
    "    - predict the labels on the validation set\n",
    "    - calculate the prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "210797f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-547.        , -405.85714286,  -67.        ,  -31.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(\n",
    "    pipeline, \n",
    "    X = df_train[[\"win\", \"summer\"]], \n",
    "    y = df_train[\"price\"], \n",
    "    cv=4, \n",
    "    scoring=\"neg_mean_squared_error\" # higher is better for score\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5c8a9",
   "metadata": {},
   "source": [
    "So an overall estimate of test MSE is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8941629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(262.7142857142857)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci112 (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
